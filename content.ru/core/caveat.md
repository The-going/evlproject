---
menuTitle: "Предостережение"
title: "Это вы определенно хотите знать"
weight: 7
original_path: "content/core/caveat.md"
original_hash: "129a74f"
---

## Общие вопросы

### `isolcpus` это тоже наш друг {#caveat-isocpus}

Изолировать некоторые процессоры в командной строке ядра с помощью опции
_isolcpus=_, чтобы не допустить, чтобы балансировщик нагрузки перегружал на них
внутриполосную работу, - это не только хорошая идея с
[PREEMPT_RT](https://wiki.linuxfoundation.org/realtime/rtl/blog), но и для
любого инструмента настройки двойного ядра.

Таким образом, некоторая случайная внутриполосная работа по удалению строк кэша
на процессоре, где потоки реального времени ненадолго отключаются, менее вероятна,
что увеличивает вероятность дорогостоящих пропусков кэша, что положительно
сказывается на значениях задержек, которые вы можете получить. Даже если
небольшое ядро EVL имеет ограниченную подверженность воздействию такого рода помех,
экономия нескольких микросекунд стоит того, когда наихудший показатель
уже находится в пределах десятых долей микросекунд.

### `CONFIG_DEBUG_HARD_LOCKS` это круто, но разрушает гарантии в реальном времени

Когда включена функция `CONFIG_DEBUG_HARD_LOCKS`, механизм зависимостей
блокировки (`CONFIG_LOCKDEP`), который помогает отслеживать взаимоблокировки и
другие проблемы, связанные с блокировками, также включен для
[жестких блокировок]({{% relref "dovetail/pipeline/locking#new-spinlocks" %}})
Ласточкиного хвоста (Dovetail), который лежит в основе большинства механизмов
сериализации, используемых ядром EVL.

Это хорошо, так как у него есть валидатор блокировки, который также контролирует
жесткие блокировки, используемые EVL. Однако это связано с высокой ценой с точки
зрения задержки: не редкость видеть сотни микросекунд, проведенных в валидаторе,
время от времени с жесткими прерываниями. Запуск утилиты мониторинга задержки
(она же `latmus`) которая является частью `libevl` в этой конфигурации, должен
дать вам довольно уродливые цифры.

Короче говоря, это нормально, если включить `CONFIG_DEBUG_HARD_LOCKS` для отладки
некоторого шаблона блокировки в EVL, но вы не сможете одновременно выполнять
требования в режиме реального времени в такой конфигурации.

### Масштабирование частоты процессора (обычно) оказывает негативное влияние на задержку {#caveat-cpufreq}

Включение регулятора _ondemand_ CPUFreq - или любого регулятора, выполняющего
динамическую настройку частоты процессора, - может привести к значительной
задержке EVL в вашей системе, от десяти микросекунд до более чем ста
в зависимости от оборудования. Выбор так называемого регулятора производительности
(_performance_) является безопасным вариантом, который гарантирует, что никогда
не произойдет никакого частотного перехода, сохраняя процессоры на максимальной
скорости обработки.

Другими словами, если `CONFIG_CPU_FREQ` должен быть включен в вашей конфигурации,
включение исключительно `CONFIG_CPU_FREQ_DEFAULT_GOV_PERFORMANCE` и
`CONFIG_CPU_FREQ_GOV_PERFORMANCE` чаще всего является лучшим способом
предотвращения неожиданно высоких пиков задержки.

### Отключите `CONFIG_SMP` для лучшей задержки в одноядерных системах

На одноядерном оборудовании может по-прежнему выполняться некоторый
нестандартный код для работы с различными типами спин-блокировок с помощью
сборки SMP, что приводит к дополнительным ветвям процессора и пропускам кэша.
На низкоуровневом оборудовании эти накладные расходы могут быть заметны.

Поэтому, если вам не нужна поддержка SMP или параметры отладки ядра
которые зависят от инструментирования конструкций spinlock (например
`CONFIG_DEBUG_PREEMPT`), вы можете отключить все связанные параметры ядра,
начиная с `CONFIG_SMP`.

## Проблемы, связанные с архитектурой

### x86 {#x86-caveat}

- GCC 10.x может генерировать код, вызывающий преждевременный сбой процесса
  загрузки SMP, как сообщается в [этом сообщении](https://lkml.org/lkml/2020/3/14/186).
  В качестве обходного решения вы можете отключить `CONFIG_STACKPROTECTOR_STRONG`
  в конфигурации ядра.

- `CONFIG_ACPI_PROCESSOR_IDLE` может увеличить задержку при пробуждении по IRQ
  из режима ожидания на некоторых SoC (до 30 наблюдаемых нами) на x86. Этот
  параметр неявно выбирается следующей цепочкой конфигурации:
  `CONFIG_SCHED_MC_PRIO` &#8594; `CONFIG_INTEL_PSTATE` &#8594;
  `CONFIG_ACPI_PROCESSOR`. Если на вашем оборудовании x86 наблюдаются показатели
  задержки вне диапазона, отключение этой цепочки может помочь.

- Когда HPET отключен, сторожевой таймер, который отслеживает работоспособность
  текущего источника синхронизации (clocksource) для ядра, может использовать
  _refined-jiffies_ в качестве эталонного источника синхронизации для сравнения.
  К сожалению, такой источник синхронизации довольно неточен для хронометража,
  так как прерывания таймера могут быть пропущены. Это, в свою очередь, может
  вызвать ложные срабатывания сторожевого таймера, что в конечном итоге приведет
  к объявлению источника синхронизации TSC 'нестабильным'. Например, было замечено,
  что включение `CONFIG_FUNCTION_GRAPH_TRACER` на некотором устаревшем
  оборудовании будет систематически вызывать такое поведение при загрузке.
  Следующее предупреждение, появляющееся в журнале ядра, является симптомом этой
  проблемы:

  ```mk
  clocksource: timekeeping watchdog on CPU0: Marking clocksource
               'tsc-early' as unstable because the skew is too large:
  clocksource: 'refined-jiffies' wd_now: fffb7018 wd_last: fffb6e9d
               mask: ffffffff
  clocksource: 'tsc-early' cs_now: 68a6a7070f6a0 cs_last: 68a69ab6f74d6
               mask: ffffffffffffffff
  tsc: Marking TSC unstable due to clocksource watchdog
  ```

  Это проблема, потому что TSC является источником синхронизации с лучшим
  рейтингом и напрямую доступен из vDSO,]({{< relref
  "dovetail/porting/clocksource#time-vdso-access" >}}), что ускоряет операции с
  отметкой времени. Если известно, что TSC на вашем оборудовании в порядке и, тем
  не менее, вы столкнулись с этой проблемой, вы можете передать `tsc=nowatchdog`
  ядру, чтобы предотвратить это, или даже `tsc=reliable`, если все TSC достаточно
  надежны для синхронизации между процессорами. Если TSC действительно нестабилен
  на каком-либо устаревшем оборудовании, и вы не можете игнорировать предупреждение
  сторожевого таймера, вы все равно можете оставить его другим источникам
  синхронизации, таким как  _acpi\_pm_. Вызовы [evl_read_clock()]({{<
  relref "core/user-api/clock/_index.md#evl_read_clock" >}}) были бы медленнее по
  сравнению с прямым считыванием без системного вызова из vDSO, но ядру EVL, тем
  не менее, удалось бы получить временные метки из своих [встроенных
  часов]({{< relref "core/user-api/clock/_index.md#builtin-clocks" >}}) за счет
  внеполосного системного вызова, хотя и без участия внутриполосной стадии.
  Вы определенно хотите убедиться, что на вашей платформе все правильно в
  отношении считывания временных меток, запустив тест
  [latmus]({{< relref "core/testing#latmus-program" >}}), который может
  обнаружить любую связанную с этим проблему.

  Вы можете получить текущий источник синхронизации, используемый ядром, следующим образом:

  ```sh
  # cat /sys/devices/system/clocksource/clocksource0/current_clocksource
  tsc
  ```

- Сбор данных _perf_ на основе NMI может привести к тому, что ядро будет выполнять
  крайне медленный код драйвера ACPI при каждом событии. Поскольку отключение
  `CONFIG_PERF` не является опцией, передача `nmi_watchdog=0` в командной строке
  ядра при загрузке может помочь.

{{% notice warning %}}
Передача `nmi_watchdog=0` отключает обнаружение жесткой блокировки для
внутриполосного ядра. Однако EVL по-прежнему будет обнаруживать запущенные
потоки EVL, застрявшие во внеполосном выполнении, если включена функция
`CONFIG_EVL_WATCHDOG`.
{{% /notice %}}

---

{{<lastmodified>}}
{{<last-ru-modified>}}
